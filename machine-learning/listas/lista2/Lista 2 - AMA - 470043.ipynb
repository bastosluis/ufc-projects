{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Lista 2 - AMA - 470043.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyP7CwMfpHWM7NYXOQ3OQV3n"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Lista 2 - AMA - Luis Fernando Bastos Rego - 470043\n","#Apresentação dos modelos:"],"metadata":{"id":"ajic1Zmh7sox"}},{"cell_type":"code","execution_count":4,"metadata":{"id":"4acz2yAVdoYR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1652400535141,"user_tz":180,"elapsed":290,"user":{"displayName":"Luis Fernando","userId":"06406872266196398918"}},"outputId":"0a475d2a-be55-4ea4-c620-cc1b65899565"},"outputs":[{"output_type":"stream","name":"stdout","text":["Número de amostras: 569\n","Número de dimensões: 31\n","Número de classes: 2\n","Número de folds: 10\n"]}],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn import metrics\n","# implementações feitas por mim\n","import modelslib as model\n","import norm\n","import training\n","\n","dataset = np.genfromtxt('./breastcancer.csv', delimiter=',')\n","\n","fold_list = training.kfold(10, dataset)\n","logreg_param = []\n","nbg_param = []\n","gda_param = []\n","\n","logreg_pred = []\n","nbg_pred = []\n","gda_pred = []\n","\n","model_names = [ 'LR', 'GDA', 'NBG' ]\n","models_param = [ logreg_param, gda_param, nbg_param ]\n","model_preds = [ logreg_pred, gda_pred, nbg_pred ]\n","\n","print(f\"Número de amostras: {dataset.shape[0]}\")\n","print(f\"Número de dimensões: {dataset.shape[1]}\")\n","print(f\"Número de classes: {np.unique(dataset[:,[-1]]).shape[0]}\")\n","print(f\"Número de folds: {len(fold_list)}\")"]},{"cell_type":"markdown","source":["* Para fazer a média e o desvio padrão de todas as 4 métricas para cada modelo, usaremos matrizes de dimensão 3 x 10:"],"metadata":{"id":"oNEEeZaEvF1-"}},{"cell_type":"code","source":["# Inicializando métricas:\n","# Listas de Listas de métricas para cada modelo (são 3, divididos em 10-fold totalizando 30)\n","acurracy_matrix = [[],[],[]]\n","precision_matrix = [[],[],[]]\n","f1score_matrix = [[],[],[]]\n","recall_matrix = [[],[],[]]\n","# Lista para guardar os testes de cada fold, em formato de tupla (x,y):\n","fold_test_list = []"],"metadata":{"id":"QTaxEkOnvFNg","executionInfo":{"status":"ok","timestamp":1652400999171,"user_tz":180,"elapsed":270,"user":{"displayName":"Luis Fernando","userId":"06406872266196398918"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["* Utilizando os folds com cada modelo:"],"metadata":{"id":"fU48FHAsC2cZ"}},{"cell_type":"code","source":["for i in range(len(fold_list)):\n","\n","    # Filtragem dos dados por cada fold: \n","    train_dataset = dataset[fold_list[i].reshape(-1) == True] \n","    test_dataset = dataset[fold_list[i].reshape(-1) == False]\n","    x_train = train_dataset[:,:-1]\n","    y_train = train_dataset[:,[-1]]\n","    x_test = test_dataset[:,:-1]\n","    y_test = test_dataset[:,[-1]]\n","    # Guarda-se o grupo de teste:\n","    fold_test_list.append((x_test,y_test))\n","    # Normalizando x:\n","    x_scaled = norm.normalize(x_train)\n","    x_test_scaled = norm.normalize(x_test)\n","    # Aplicando a coluna de 1s\n","    x_scaled = np.c_[np.ones((x_scaled.shape[0],1)), x_scaled]\n","    x_test_scaled = np.c_[np.ones((x_test_scaled.shape[0],1)), x_test_scaled]\n","\n","\n","    # Regressão Logística:\n","    w, iter_num, error_list = model.GD_logi(x_scaled, y_train)\n","    logreg_param.append(w)\n","    y_p = np.around(model.sigmoid(x_test_scaled @ w))\n","    logreg_pred.append(y_p)\n","    acurracy_matrix[0].append(metrics.accuracy_score(y_test, y_p))\n","    precision_matrix[0].append(metrics.precision_score(y_test, y_p, average='macro'))\n","    recall_matrix[0].append(metrics.recall_score(y_test, y_p, average='macro'))\n","    f1score_matrix[0].append(metrics.f1_score(y_test, y_p, average='macro'))\n","\n","    \n","    # Análise de Discriminante Gaussiano:\n","    gda_p = model.gaussian_discriminant_analysis(x_train,y_train)\n","    gda_param.append(gda_p)\n","    y_p = model.predict_gda(x_test, gda_p[0], gda_p[1], gda_p[2])\n","    gda_pred.append(y_p)\n","    acurracy_matrix[1].append(metrics.accuracy_score(y_test, y_p))\n","    precision_matrix[1].append(metrics.precision_score(y_test, y_p, average='macro'))\n","    recall_matrix[1].append(metrics.recall_score(y_test, y_p, average='macro'))\n","    f1score_matrix[1].append(metrics.f1_score(y_test, y_p, average='macro'))\n","\n","\n","    # Naive Bayes Gaussiano:\n","    nbg_p = model.naive_bayes_gaussian(x_train,y_train)\n","    nbg_param.append(nbg_p)\n","    y_p = model.predict_nbg(x_test, nbg_p[0], nbg_p[1], nbg_p[2])\n","    nbg_pred.append(y_p)\n","    acurracy_matrix[2].append(metrics.accuracy_score(y_test, y_p))\n","    precision_matrix[2].append(metrics.precision_score(y_test, y_p, average='macro'))\n","    recall_matrix[2].append(metrics.recall_score(y_test, y_p, average='macro'))\n","    f1score_matrix[2].append(metrics.f1_score(y_test, y_p, average='macro'))"],"metadata":{"id":"VUnSi-u3vtm4","executionInfo":{"status":"ok","timestamp":1652401000871,"user_tz":180,"elapsed":562,"user":{"displayName":"Luis Fernando","userId":"06406872266196398918"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["# Métricas de avaliação:"],"metadata":{"id":"52LgAJkTFGlM"}},{"cell_type":"code","source":["# Medições:\n","for i in range(len(model_names)):\n","    \n","    print(f'\\nAverage score in 10-fold training for {model_names[i]}:\\n')\n","    print(f'Accuracy:   {np.mean(acurracy_matrix[i]):.2f}, with standard deviation: {np.std(acurracy_matrix[i]):.2f};')\n","    print(f'Precision:  {np.mean(precision_matrix[i]):.2f}, with standard deviation: {np.std(precision_matrix[i]):.2f};')\n","    print(f'Recall:     {np.mean(recall_matrix[i]):.2f}, with standard deviation: {np.std(recall_matrix[i]):.2f};')\n","    print(f'F1:         {np.mean(f1score_matrix[i]):.2f}, with standard deviation: {np.std(f1score_matrix[i]):.2f};\\n')\n"],"metadata":{"id":"9GSbegUUFIfC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1652400544017,"user_tz":180,"elapsed":283,"user":{"displayName":"Luis Fernando","userId":"06406872266196398918"}},"outputId":"779e7ae8-54c2-4e01-ae04-95f8a0c692ab"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Average score in 10-fold training for LR:\n","\n","Accuracy:   0.91, with standard deviation: 0.08;\n","Precision:  0.89, with standard deviation: 0.08;\n","Recall:     0.93, with standard deviation: 0.05;\n","F1:         0.90, with standard deviation: 0.09;\n","\n","\n","Average score in 10-fold training for GDA:\n","\n","Accuracy:   0.96, with standard deviation: 0.01;\n","Precision:  0.94, with standard deviation: 0.02;\n","Recall:     0.96, with standard deviation: 0.02;\n","F1:         0.95, with standard deviation: 0.02;\n","\n","\n","Average score in 10-fold training for NBG:\n","\n","Accuracy:   0.93, with standard deviation: 0.04;\n","Precision:  0.91, with standard deviation: 0.05;\n","Recall:     0.92, with standard deviation: 0.04;\n","F1:         0.91, with standard deviation: 0.04;\n","\n"]}]},{"cell_type":"markdown","source":["Caso seja interessante testar cada fold individualmente, pode-se usar esse fragmento de código apenas mudando as variáveis fold e model."],"metadata":{"id":"oENiHYm_wKb_"}},{"cell_type":"code","source":["model = 0\n","fold = 0\n","print(f\"Summary for the classifier {model_names[model]} (Fold {fold+1}) with accuracy {metrics.accuracy_score(fold_test_list[fold][1], model_preds[model][fold]):.2f}\")\n","print(metrics.classification_report(fold_test_list[fold][1], model_preds[model][fold]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lYt5Si8bwceP","executionInfo":{"status":"ok","timestamp":1652401387035,"user_tz":180,"elapsed":277,"user":{"displayName":"Luis Fernando","userId":"06406872266196398918"}},"outputId":"f6faa327-0082-46fd-cd5e-9af4a2c7c5d2"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Summary for the classifier LR (Fold 1) with accuracy 0.70\n","              precision    recall  f1-score   support\n","\n","         0.0       1.00      0.63      0.77        46\n","         1.0       0.39      1.00      0.56        11\n","\n","    accuracy                           0.70        57\n","   macro avg       0.70      0.82      0.67        57\n","weighted avg       0.88      0.70      0.73        57\n","\n"]}]}]}